{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2d48ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     2\n",
      "1     4\n",
      "2     6\n",
      "3     8\n",
      "4    10\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# create and display a one-dimensional array-like object containing an array of data\n",
    "import pandas as pd\n",
    "l=[2, 4, 6, 8, 10]\n",
    "ds = pd.Series([2, 4, 6, 8, 10])\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca5e7ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add two Series:\n",
      "0     3\n",
      "1     7\n",
      "2    11\n",
      "3    15\n",
      "4    19\n",
      "dtype: int64\n",
      "Subtract two Series:\n",
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "dtype: int64\n",
      "Multiply two Series:\n",
      "0     2\n",
      "1    12\n",
      "2    30\n",
      "3    56\n",
      "4    90\n",
      "dtype: int64\n",
      "Divide Series1 by Series2:\n",
      "0    2.000000\n",
      "1    1.333333\n",
      "2    1.200000\n",
      "3    1.142857\n",
      "4    1.111111\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "ds1 = pd.Series([2, 4, 6, 8, 10])\n",
    "ds2 = pd.Series([1, 3, 5, 7, 9])\n",
    "ds = ds1 + ds2\n",
    "print(\"Add two Series:\")\n",
    "print(ds)\n",
    "print(\"Subtract two Series:\")\n",
    "ds = ds1 - ds2\n",
    "print(ds)\n",
    "print(\"Multiply two Series:\")\n",
    "ds = ds1 * ds2\n",
    "print(ds)\n",
    "print(\"Divide Series1 by Series2:\")\n",
    "ds = ds1 / ds2\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d98d32d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dictionary:\n",
      "{'a': 100, 'b': 200, 'c': 300, 'd': 400, 'e': 800}\n",
      "Converted series:\n",
      "a    100\n",
      "b    200\n",
      "c    300\n",
      "d    400\n",
      "e    800\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#convert a dictionary to a Pandas series\n",
    "import pandas as pd\n",
    "d1 = {'a': 100, 'b': 200, 'c':300, 'd':400, 'e':800}\n",
    "print(\"Original dictionary:\")\n",
    "print(d1)\n",
    "new_series = pd.Series(d1)\n",
    "print(\"Converted series:\")\n",
    "print(new_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553fd791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert a NumPy array to a Pandas series\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "np_array = np.array([10, 20, 30, 40, 50])\n",
    "print(\"NumPy array:\")\n",
    "print(np_array)\n",
    "new_series = pd.Series(np_array)\n",
    "print(\"Converted Pandas series:\")\n",
    "print(new_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3335c880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the default index and set a column as an Index in a given dataframe\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({\n",
    "    'school_code': ['s001','s002','s003','s001','s002','s004'],\n",
    "    'class': ['V', 'V', 'VI', 'VI', 'V', 'VI'],\n",
    "    'name': ['Alberto Franco','Gino Mcneill','Ryan Parkes', 'Eesha Hinton', 'Gino Mcneill', 'David Parkes'],\n",
    "    'date_Of_Birth': ['15/05/2002','17/05/2002','16/02/1999','25/09/1998','11/05/2002','15/09/1997'],\n",
    "    'weight': [35, 32, 33, 30, 31, 32],\n",
    "    'address': ['street1', 'street2', 'street3', 'street1', 'street2', 'street4'],\n",
    "    't_id':['t1', 't2', 't3', 't4', 't5', 't6']})\n",
    "print(\"Default Index:\")\n",
    "print(df.head(10))\n",
    "print(\"\\nschool_code as new Index:\")\n",
    "df1 = df.set_index('school_code')\n",
    "print(df1)\n",
    "print(\"\\nt_id as new Index:\")\n",
    "df2 = df.set_index('t_id')\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52515a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert all the string values to upper, lower cases in a given pandas series. Also find the length of the string values\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "s = pd.Series(['X', 'Y', 'Z', 'Aaba', 'Baca', np.nan, 'CABA', None, 'bird', 'horse', 'dog'])\n",
    "print(\"Original series:\")\n",
    "print(s)\n",
    "print(\"\\nConvert all string values of the said Series to upper case:\")\n",
    "print(s.str.upper())\n",
    "print(\"\\nConvert all string values of the said Series to lower case:\")\n",
    "print(s.str.lower())\n",
    "print(\"\\nLength of the string values of the said Series:\")\n",
    "print(s.str.len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c6d478f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0\n",
      "3  1\n",
      "4  2\n",
      "5  3\n",
      "6  4\n",
      "1  5\n"
     ]
    }
   ],
   "source": [
    "df=pd.DataFrame([1,2,3,4,5],[3,4,5,6,1])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "727204ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   variable  value\n",
       "0         0      1\n",
       "1         0      2\n",
       "2         0      3\n",
       "3         0      4\n",
       "4         0      5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.melt(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1869e4f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T',\n",
       " '_AXIS_LEN',\n",
       " '_AXIS_ORDERS',\n",
       " '_AXIS_TO_AXIS_NUMBER',\n",
       " '_HANDLED_TYPES',\n",
       " '__abs__',\n",
       " '__add__',\n",
       " '__and__',\n",
       " '__annotations__',\n",
       " '__array__',\n",
       " '__array_priority__',\n",
       " '__array_ufunc__',\n",
       " '__array_wrap__',\n",
       " '__bool__',\n",
       " '__class__',\n",
       " '__contains__',\n",
       " '__copy__',\n",
       " '__deepcopy__',\n",
       " '__delattr__',\n",
       " '__delitem__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__divmod__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__finalize__',\n",
       " '__floordiv__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__iadd__',\n",
       " '__iand__',\n",
       " '__ifloordiv__',\n",
       " '__imod__',\n",
       " '__imul__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__invert__',\n",
       " '__ior__',\n",
       " '__ipow__',\n",
       " '__isub__',\n",
       " '__iter__',\n",
       " '__itruediv__',\n",
       " '__ixor__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__matmul__',\n",
       " '__mod__',\n",
       " '__module__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__neg__',\n",
       " '__new__',\n",
       " '__nonzero__',\n",
       " '__or__',\n",
       " '__pos__',\n",
       " '__pow__',\n",
       " '__radd__',\n",
       " '__rand__',\n",
       " '__rdivmod__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rfloordiv__',\n",
       " '__rmatmul__',\n",
       " '__rmod__',\n",
       " '__rmul__',\n",
       " '__ror__',\n",
       " '__round__',\n",
       " '__rpow__',\n",
       " '__rsub__',\n",
       " '__rtruediv__',\n",
       " '__rxor__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__sub__',\n",
       " '__subclasshook__',\n",
       " '__truediv__',\n",
       " '__weakref__',\n",
       " '__xor__',\n",
       " '_accessors',\n",
       " '_accum_func',\n",
       " '_add_numeric_operations',\n",
       " '_agg_by_level',\n",
       " '_agg_examples_doc',\n",
       " '_agg_summary_and_see_also_doc',\n",
       " '_align_frame',\n",
       " '_align_series',\n",
       " '_append',\n",
       " '_arith_method',\n",
       " '_as_manager',\n",
       " '_attrs',\n",
       " '_box_col_values',\n",
       " '_can_fast_transpose',\n",
       " '_check_inplace_and_allows_duplicate_labels',\n",
       " '_check_inplace_setting',\n",
       " '_check_is_chained_assignment_possible',\n",
       " '_check_label_or_level_ambiguity',\n",
       " '_check_setitem_copy',\n",
       " '_clear_item_cache',\n",
       " '_clip_with_one_bound',\n",
       " '_clip_with_scalar',\n",
       " '_cmp_method',\n",
       " '_combine_frame',\n",
       " '_consolidate',\n",
       " '_consolidate_inplace',\n",
       " '_construct_axes_dict',\n",
       " '_construct_axes_from_arguments',\n",
       " '_construct_result',\n",
       " '_constructor',\n",
       " '_constructor_sliced',\n",
       " '_convert',\n",
       " '_count_level',\n",
       " '_data',\n",
       " '_dir_additions',\n",
       " '_dir_deletions',\n",
       " '_dispatch_frame_op',\n",
       " '_drop_axis',\n",
       " '_drop_labels_or_levels',\n",
       " '_ensure_valid_index',\n",
       " '_find_valid_index',\n",
       " '_flags',\n",
       " '_from_arrays',\n",
       " '_from_mgr',\n",
       " '_get_agg_axis',\n",
       " '_get_axis',\n",
       " '_get_axis_name',\n",
       " '_get_axis_number',\n",
       " '_get_axis_resolvers',\n",
       " '_get_block_manager_axis',\n",
       " '_get_bool_data',\n",
       " '_get_cleaned_column_resolvers',\n",
       " '_get_column_array',\n",
       " '_get_index_resolvers',\n",
       " '_get_item_cache',\n",
       " '_get_label_or_level_values',\n",
       " '_get_numeric_data',\n",
       " '_get_value',\n",
       " '_getitem_bool_array',\n",
       " '_getitem_multilevel',\n",
       " '_gotitem',\n",
       " '_hidden_attrs',\n",
       " '_indexed_same',\n",
       " '_info_axis',\n",
       " '_info_axis_name',\n",
       " '_info_axis_number',\n",
       " '_info_repr',\n",
       " '_init_mgr',\n",
       " '_inplace_method',\n",
       " '_internal_names',\n",
       " '_internal_names_set',\n",
       " '_is_copy',\n",
       " '_is_homogeneous_type',\n",
       " '_is_label_or_level_reference',\n",
       " '_is_label_reference',\n",
       " '_is_level_reference',\n",
       " '_is_mixed_type',\n",
       " '_is_view',\n",
       " '_iset_item',\n",
       " '_iset_item_mgr',\n",
       " '_iset_not_inplace',\n",
       " '_item_cache',\n",
       " '_iter_column_arrays',\n",
       " '_ixs',\n",
       " '_join_compat',\n",
       " '_logical_func',\n",
       " '_logical_method',\n",
       " '_maybe_cache_changed',\n",
       " '_maybe_update_cacher',\n",
       " '_metadata',\n",
       " '_mgr',\n",
       " '_min_count_stat_function',\n",
       " '_needs_reindex_multi',\n",
       " '_protect_consolidate',\n",
       " '_reduce',\n",
       " '_reduce_axis1',\n",
       " '_reindex_axes',\n",
       " '_reindex_columns',\n",
       " '_reindex_index',\n",
       " '_reindex_multi',\n",
       " '_reindex_with_indexers',\n",
       " '_rename',\n",
       " '_replace_columnwise',\n",
       " '_repr_data_resource_',\n",
       " '_repr_fits_horizontal_',\n",
       " '_repr_fits_vertical_',\n",
       " '_repr_html_',\n",
       " '_repr_latex_',\n",
       " '_reset_cache',\n",
       " '_reset_cacher',\n",
       " '_sanitize_column',\n",
       " '_series',\n",
       " '_set_axis',\n",
       " '_set_axis_name',\n",
       " '_set_axis_nocheck',\n",
       " '_set_is_copy',\n",
       " '_set_item',\n",
       " '_set_item_frame_value',\n",
       " '_set_item_mgr',\n",
       " '_set_value',\n",
       " '_setitem_array',\n",
       " '_setitem_frame',\n",
       " '_setitem_slice',\n",
       " '_slice',\n",
       " '_stat_axis',\n",
       " '_stat_axis_name',\n",
       " '_stat_axis_number',\n",
       " '_stat_function',\n",
       " '_stat_function_ddof',\n",
       " '_take_with_is_copy',\n",
       " '_to_dict_of_blocks',\n",
       " '_typ',\n",
       " '_update_inplace',\n",
       " '_validate_dtype',\n",
       " '_values',\n",
       " '_where',\n",
       " 'abs',\n",
       " 'add',\n",
       " 'add_prefix',\n",
       " 'add_suffix',\n",
       " 'agg',\n",
       " 'aggregate',\n",
       " 'align',\n",
       " 'all',\n",
       " 'any',\n",
       " 'append',\n",
       " 'apply',\n",
       " 'applymap',\n",
       " 'asfreq',\n",
       " 'asof',\n",
       " 'assign',\n",
       " 'astype',\n",
       " 'at',\n",
       " 'at_time',\n",
       " 'attrs',\n",
       " 'axes',\n",
       " 'backfill',\n",
       " 'between_time',\n",
       " 'bfill',\n",
       " 'bool',\n",
       " 'boxplot',\n",
       " 'clip',\n",
       " 'columns',\n",
       " 'combine',\n",
       " 'combine_first',\n",
       " 'compare',\n",
       " 'convert_dtypes',\n",
       " 'copy',\n",
       " 'corr',\n",
       " 'corrwith',\n",
       " 'count',\n",
       " 'cov',\n",
       " 'cummax',\n",
       " 'cummin',\n",
       " 'cumprod',\n",
       " 'cumsum',\n",
       " 'describe',\n",
       " 'diff',\n",
       " 'div',\n",
       " 'divide',\n",
       " 'dot',\n",
       " 'drop',\n",
       " 'drop_duplicates',\n",
       " 'droplevel',\n",
       " 'dropna',\n",
       " 'dtypes',\n",
       " 'duplicated',\n",
       " 'empty',\n",
       " 'eq',\n",
       " 'equals',\n",
       " 'eval',\n",
       " 'ewm',\n",
       " 'expanding',\n",
       " 'explode',\n",
       " 'ffill',\n",
       " 'fillna',\n",
       " 'filter',\n",
       " 'first',\n",
       " 'first_valid_index',\n",
       " 'flags',\n",
       " 'floordiv',\n",
       " 'from_dict',\n",
       " 'from_records',\n",
       " 'ge',\n",
       " 'get',\n",
       " 'groupby',\n",
       " 'gt',\n",
       " 'head',\n",
       " 'hist',\n",
       " 'iat',\n",
       " 'idxmax',\n",
       " 'idxmin',\n",
       " 'iloc',\n",
       " 'index',\n",
       " 'infer_objects',\n",
       " 'info',\n",
       " 'insert',\n",
       " 'interpolate',\n",
       " 'isin',\n",
       " 'isna',\n",
       " 'isnull',\n",
       " 'items',\n",
       " 'iteritems',\n",
       " 'iterrows',\n",
       " 'itertuples',\n",
       " 'join',\n",
       " 'keys',\n",
       " 'kurt',\n",
       " 'kurtosis',\n",
       " 'last',\n",
       " 'last_valid_index',\n",
       " 'le',\n",
       " 'loc',\n",
       " 'lookup',\n",
       " 'lt',\n",
       " 'mad',\n",
       " 'mask',\n",
       " 'max',\n",
       " 'mean',\n",
       " 'median',\n",
       " 'melt',\n",
       " 'memory_usage',\n",
       " 'merge',\n",
       " 'min',\n",
       " 'mod',\n",
       " 'mode',\n",
       " 'mul',\n",
       " 'multiply',\n",
       " 'ndim',\n",
       " 'ne',\n",
       " 'nlargest',\n",
       " 'notna',\n",
       " 'notnull',\n",
       " 'nsmallest',\n",
       " 'nunique',\n",
       " 'pad',\n",
       " 'pct_change',\n",
       " 'pipe',\n",
       " 'pivot',\n",
       " 'pivot_table',\n",
       " 'plot',\n",
       " 'pop',\n",
       " 'pow',\n",
       " 'prod',\n",
       " 'product',\n",
       " 'quantile',\n",
       " 'query',\n",
       " 'radd',\n",
       " 'rank',\n",
       " 'rdiv',\n",
       " 'reindex',\n",
       " 'reindex_like',\n",
       " 'rename',\n",
       " 'rename_axis',\n",
       " 'reorder_levels',\n",
       " 'replace',\n",
       " 'resample',\n",
       " 'reset_index',\n",
       " 'rfloordiv',\n",
       " 'rmod',\n",
       " 'rmul',\n",
       " 'rolling',\n",
       " 'round',\n",
       " 'rpow',\n",
       " 'rsub',\n",
       " 'rtruediv',\n",
       " 'sample',\n",
       " 'select_dtypes',\n",
       " 'sem',\n",
       " 'set_axis',\n",
       " 'set_flags',\n",
       " 'set_index',\n",
       " 'shape',\n",
       " 'shift',\n",
       " 'size',\n",
       " 'skew',\n",
       " 'slice_shift',\n",
       " 'sort_index',\n",
       " 'sort_values',\n",
       " 'squeeze',\n",
       " 'stack',\n",
       " 'std',\n",
       " 'style',\n",
       " 'sub',\n",
       " 'subtract',\n",
       " 'sum',\n",
       " 'swapaxes',\n",
       " 'swaplevel',\n",
       " 'tail',\n",
       " 'take',\n",
       " 'to_clipboard',\n",
       " 'to_csv',\n",
       " 'to_dict',\n",
       " 'to_excel',\n",
       " 'to_feather',\n",
       " 'to_gbq',\n",
       " 'to_hdf',\n",
       " 'to_html',\n",
       " 'to_json',\n",
       " 'to_latex',\n",
       " 'to_markdown',\n",
       " 'to_numpy',\n",
       " 'to_parquet',\n",
       " 'to_period',\n",
       " 'to_pickle',\n",
       " 'to_records',\n",
       " 'to_sql',\n",
       " 'to_stata',\n",
       " 'to_string',\n",
       " 'to_timestamp',\n",
       " 'to_xarray',\n",
       " 'to_xml',\n",
       " 'transform',\n",
       " 'transpose',\n",
       " 'truediv',\n",
       " 'truncate',\n",
       " 'tz_convert',\n",
       " 'tz_localize',\n",
       " 'unstack',\n",
       " 'update',\n",
       " 'value_counts',\n",
       " 'values',\n",
       " 'var',\n",
       " 'where',\n",
       " 'xs']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1c8aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename('h':'height')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e12f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "1.program to rename columns of a  given dataframe\n",
    "x,y,z\n",
    "2.program to change the order of Dataframe columns\n",
    "3.program to replace all the NaN values with zeros in a column of a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d1020e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrames:\n",
      "  student_id              name  marks\n",
      "0         S1  Danniella Fenton    200\n",
      "1         S2      Ryder Storey    210\n",
      "2         S3      Bryce Jensen    190\n",
      "3         S4         Ed Bernal    222\n",
      "4         S5       Kwame Morin    199\n",
      "-------------------------------------\n",
      "  student_id              name  marks\n",
      "0         S4  Scarlette Fisher    201\n",
      "1         S5  Carla Williamson    200\n",
      "2         S6       Dante Morse    198\n",
      "3         S7    Kaiser William    219\n",
      "4         S8   Madeeha Preston    201\n",
      "\n",
      "Join the said two dataframes along rows:\n",
      "  student_id              name  marks\n",
      "0         S1  Danniella Fenton    200\n",
      "1         S2      Ryder Storey    210\n",
      "2         S3      Bryce Jensen    190\n",
      "3         S4         Ed Bernal    222\n",
      "4         S5       Kwame Morin    199\n",
      "0         S4  Scarlette Fisher    201\n",
      "1         S5  Carla Williamson    200\n",
      "2         S6       Dante Morse    198\n",
      "3         S7    Kaiser William    219\n",
      "4         S8   Madeeha Preston    201\n"
     ]
    }
   ],
   "source": [
    "#program to join the two given dataframes along rows and assign all data\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "student_data1 = pd.DataFrame({\n",
    "        'student_id': ['S1', 'S2', 'S3', 'S4', 'S5'],\n",
    "         'name': ['Danniella Fenton', 'Ryder Storey', 'Bryce Jensen', 'Ed Bernal', 'Kwame Morin'], \n",
    "        'marks': [200, 210, 190, 222, 199]})\n",
    "\n",
    "student_data2 = pd.DataFrame({\n",
    "        'student_id': ['S4', 'S5', 'S6', 'S7', 'S8'],\n",
    "        'name': ['Scarlette Fisher', 'Carla Williamson', 'Dante Morse', 'Kaiser William', 'Madeeha Preston'], \n",
    "        'marks': [201, 200, 198, 219, 201]})\n",
    "\n",
    "print(\"Original DataFrames:\")\n",
    "print(student_data1)\n",
    "print(\"-------------------------------------\")\n",
    "print(student_data2)\n",
    "print(\"\\nJoin the said two dataframes along rows:\")\n",
    "result_data = pd.concat([student_data1, student_data2])\n",
    "print(result_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "030225aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrames:\n",
      "  student_id              name  marks\n",
      "0         S1  Danniella Fenton    200\n",
      "1         S2      Ryder Storey    210\n",
      "2         S3      Bryce Jensen    190\n",
      "3         S4         Ed Bernal    222\n",
      "4         S5       Kwame Morin    199\n",
      "-------------------------------------\n",
      "  student_id              name  marks\n",
      "0         S4  Scarlette Fisher    201\n",
      "1         S5  Carla Williamson    200\n",
      "2         S6       Dante Morse    198\n",
      "3         S7    Kaiser William    219\n",
      "4         S8   Madeeha Preston    201\n",
      "\n",
      "Join the said two dataframes along columns:\n",
      "  student_id              name  marks student_id              name  marks\n",
      "0         S1  Danniella Fenton    200         S4  Scarlette Fisher    201\n",
      "1         S2      Ryder Storey    210         S5  Carla Williamson    200\n",
      "2         S3      Bryce Jensen    190         S6       Dante Morse    198\n",
      "3         S4         Ed Bernal    222         S7    Kaiser William    219\n",
      "4         S5       Kwame Morin    199         S8   Madeeha Preston    201\n"
     ]
    }
   ],
   "source": [
    "# program to join the two given dataframes along columns and assign all data\n",
    "import pandas as pd\n",
    "\n",
    "student_data1 = pd.DataFrame({\n",
    "        'student_id': ['S1', 'S2', 'S3', 'S4', 'S5'],\n",
    "         'name': ['Danniella Fenton', 'Ryder Storey', 'Bryce Jensen', 'Ed Bernal', 'Kwame Morin'], \n",
    "        'marks': [200, 210, 190, 222, 199]})\n",
    "\n",
    "student_data2 = pd.DataFrame({\n",
    "        'student_id': ['S4', 'S5', 'S6', 'S7', 'S8'],\n",
    "        'name': ['Scarlette Fisher', 'Carla Williamson', 'Dante Morse', 'Kaiser William', 'Madeeha Preston'], \n",
    "        'marks': [201, 200, 198, 219, 201]})\n",
    "\n",
    "print(\"Original DataFrames:\")\n",
    "print(student_data1)\n",
    "print(\"-------------------------------------\")\n",
    "print(student_data2)\n",
    "print(\"\\nJoin the said two dataframes along columns:\")\n",
    "result_data = pd.concat([student_data1, student_data2], axis = 1)\n",
    "print(result_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af8ba4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrames:\n",
      "  student_id              name  marks\n",
      "0         S1  Danniella Fenton    200\n",
      "1         S2      Ryder Storey    210\n",
      "2         S3      Bryce Jensen    190\n",
      "3         S4         Ed Bernal    222\n",
      "4         S5       Kwame Morin    199\n",
      "  student_id              name  marks\n",
      "0         S4  Scarlette Fisher    201\n",
      "1         S5  Carla Williamson    200\n",
      "2         S6       Dante Morse    198\n",
      "3         S7    Kaiser William    219\n",
      "4         S8   Madeeha Preston    201\n",
      "   student_id  exam_id\n",
      "0          S1       23\n",
      "1          S2       45\n",
      "2          S3       12\n",
      "3          S4       67\n",
      "4          S5       21\n",
      "5          S7       55\n",
      "6          S8       33\n",
      "7          S9       14\n",
      "8         S10       56\n",
      "9         S11       83\n",
      "10        S12       88\n",
      "11        S13       12\n",
      "\n",
      "Join first two said dataframes along rows:\n",
      "  student_id              name  marks\n",
      "0         S1  Danniella Fenton    200\n",
      "1         S2      Ryder Storey    210\n",
      "2         S3      Bryce Jensen    190\n",
      "3         S4         Ed Bernal    222\n",
      "4         S5       Kwame Morin    199\n",
      "0         S4  Scarlette Fisher    201\n",
      "1         S5  Carla Williamson    200\n",
      "2         S6       Dante Morse    198\n",
      "3         S7    Kaiser William    219\n",
      "4         S8   Madeeha Preston    201\n",
      "\n",
      "Now join the said result_data and df_exam_data along student_id:\n",
      "  student_id              name  marks  exam_id\n",
      "0         S1  Danniella Fenton    200       23\n",
      "1         S2      Ryder Storey    210       45\n",
      "2         S3      Bryce Jensen    190       12\n",
      "3         S4         Ed Bernal    222       67\n",
      "4         S4  Scarlette Fisher    201       67\n",
      "5         S5       Kwame Morin    199       21\n",
      "6         S5  Carla Williamson    200       21\n",
      "7         S7    Kaiser William    219       55\n",
      "8         S8   Madeeha Preston    201       33\n"
     ]
    }
   ],
   "source": [
    "#program to join the two given dataframes along rows and merge with another dataframe along the common column id\n",
    "\n",
    "import pandas as pd\n",
    "student_data1 = pd.DataFrame({\n",
    "        'student_id': ['S1', 'S2', 'S3', 'S4', 'S5'],\n",
    "         'name': ['Danniella Fenton', 'Ryder Storey', 'Bryce Jensen', 'Ed Bernal', 'Kwame Morin'], \n",
    "        'marks': [200, 210, 190, 222, 199]})\n",
    "\n",
    "student_data2 = pd.DataFrame({\n",
    "        'student_id': ['S4', 'S5', 'S6', 'S7', 'S8'],\n",
    "        'name': ['Scarlette Fisher', 'Carla Williamson', 'Dante Morse', 'Kaiser William', 'Madeeha Preston'], \n",
    "        'marks': [201, 200, 198, 219, 201]})\n",
    "\n",
    "exam_data = pd.DataFrame({\n",
    "        'student_id': ['S1', 'S2', 'S3', 'S4', 'S5', 'S7', 'S8', 'S9', 'S10', 'S11', 'S12', 'S13'],\n",
    "        'exam_id': [23, 45, 12, 67, 21, 55, 33, 14, 56, 83, 88, 12]})\n",
    "\n",
    "print(\"Original DataFrames:\")\n",
    "print(student_data1)\n",
    "print(student_data2)\n",
    "print(exam_data)\n",
    "\n",
    "print(\"\\nJoin first two said dataframes along rows:\")\n",
    "result_data = pd.concat([student_data1, student_data2])\n",
    "print(result_data)\n",
    "\n",
    "print(\"\\nNow join the said result_data and df_exam_data along student_id:\")\n",
    "final_merged_data = pd.merge(result_data, exam_data, on='student_id')\n",
    "print(final_merged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbe7925e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrames:\n",
      "  student_id              name  marks\n",
      "0         S1  Danniella Fenton    200\n",
      "1         S2      Ryder Storey    210\n",
      "2         S3      Bryce Jensen    190\n",
      "3         S4         Ed Bernal    222\n",
      "4         S5       Kwame Morin    199\n",
      "  student_id              name  marks\n",
      "0         S4  Scarlette Fisher    201\n",
      "1         S5  Carla Williamson    200\n",
      "2         S6       Dante Morse    198\n",
      "3         S7    Kaiser William    219\n",
      "4         S8   Madeeha Preston    201\n",
      "Merged data (inner join):\n",
      "  student_id       name_x  marks_x            name_y  marks_y\n",
      "0         S4    Ed Bernal      222  Scarlette Fisher      201\n",
      "1         S5  Kwame Morin      199  Carla Williamson      200\n"
     ]
    }
   ],
   "source": [
    "#join the two dataframes using the common column of both dataframes\n",
    "\n",
    "import pandas as pd\n",
    "student_data1 = pd.DataFrame({\n",
    "        'student_id': ['S1', 'S2', 'S3', 'S4', 'S5'],\n",
    "         'name': ['Danniella Fenton', 'Ryder Storey', 'Bryce Jensen', 'Ed Bernal', 'Kwame Morin'], \n",
    "        'marks': [200, 210, 190, 222, 199]})\n",
    "\n",
    "student_data2 = pd.DataFrame({\n",
    "        'student_id': ['S4', 'S5', 'S6', 'S7', 'S8'],\n",
    "        'name': ['Scarlette Fisher', 'Carla Williamson', 'Dante Morse', 'Kaiser William', 'Madeeha Preston'], \n",
    "        'marks': [201, 200, 198, 219, 201]})\n",
    "\n",
    "print(\"Original DataFrames:\")\n",
    "print(student_data1)\n",
    "print(student_data2)\n",
    "merged_data = pd.merge(student_data1, student_data2, on='student_id', how='inner')\n",
    "print(\"Merged data (inner join):\")\n",
    "print(merged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a3ed71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbfbb33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562ccf40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebdb695",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
